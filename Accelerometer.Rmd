---
title: "Main"
author: "Zach Quicksall (zsq2), Doyeon Kim (dkim172), Nick Favale (favale2), Wenzheng Hu(whu14)"
date: "4/10/2018"
output: html_document
---
```{r, message=FALSE, warning=FALSE}
library(rlist)
library(flexclust)
library(gbm)
library(caret)
library(ape)
library(randomForest)
```

## Data preprocessing

Load data
```{r}
# use this to load raw data
load_data = function(data_path){
  num_action = 0
  # element n is the actual name of class n
  class_to_actions = list()
  data_matrix = list()
  index = 0
  
  # each row is a file, the first element of a row is its class(1-16), the rest are flattened (through each time unit) 3 dimension data
  
  for (action in list.files(path = data_path)){
    action_path = paste(data_path, action, sep = "/")
    num_action = num_action + 1
    class_to_actions[num_action] = action
    
    for (file in list.files(path = action_path)){
      file_name = paste(action_path, file, sep = "/")
      data = read.table(file_name)
      index = index + 1
      data_matrix[[index]] = c(num_action, as.list(t(data)))
    }
  }
  
  return(data_matrix)
}
```

Process data
```{r}
fit = function(input_data, cut_size, overlap=0, num_clusters){
  cutted_signals = list()
  index = 0
  for (observation in input_data){
    index = index + 1
    cutted_signals = c(cutted_signals, cut_signal(observation[-1], cut_size, overlap))
  }
  matrix_signals = matrix(unlist(cutted_signals), ncol=3*cut_size, byrow=T)
  model = flexclust::kcca(matrix_signals, k=num_clusters, kccaFamily("kmeans"))
  
  return(model)
}

cut_signal = function(input_data, cut_size, overlap=0){
  result_data = list()
  input_data_size = length(input_data)
  input_data_idx = 1
  result_data_idx = 1

  while (input_data_idx + cut_size*3 < input_data_size){
    result_data[[result_data_idx]] = input_data[input_data_idx:(input_data_idx+cut_size*3-1)]
    input_data_idx = input_data_idx + cut_size*3 - overlap*3
    result_data_idx = result_data_idx + 1
  }
  return(result_data)
}

# the returned data is a datafrane with num_clusters+1 columns. The last column is its label.
transform = function(model, input_data, cut_size, overlap, num_clusters){
  features = list()
  index = 0
  for (observation in input_data){
    index = index + 1
    cutted_signals = cut_signal(observation[-1], cut_size, overlap)
    matrix_signals = matrix(unlist(cutted_signals), ncol=3*cut_size, byrow=T)
    pred_clusters = predict(model, matrix_signals)
    feature = count_cluster(pred_clusters, num_clusters)
    feature[num_clusters+1] = observation[1]
    features[[index]] = feature
  }
  dt_features = data.frame(matrix(unlist(features), ncol=num_clusters+1, byrow=T))
  colnames(dt_features)[num_clusters+1] = "class"
  return(dt_features)
}

count_cluster = function(pred_clusters, num_clusters){
  feature = 1:num_clusters+1
  for (i in 1:num_clusters){
    feature[i] = sum(pred_clusters==i)
  }
  return(feature)
}

# use this to process data
process_data = function(data_matrix, data_path, cut_size, overlap, num_clusters){
  model = fit(data_matrix, cut_size, overlap, num_clusters)
  data = transform(model, data_matrix, cut_size, overlap, num_clusters)
  data['class'] = as.factor(data$class)
  return(data)
}
```

Example to get processed data
```{r}
data_path = "HMP_Dataset"

# don't need to load data multiple times when tunning parameters
data_matrix_raw = load_data(data_path)

# may need to processed data several times when tuning parameters
data = process_data(data_matrix_raw, cut_size=10, overlap=0, num_clusters=10)

# test_train split
trainIndex = createDataPartition(data$class, p=0.7, list=FALSE,times=1)
data_trn = data[trainIndex,]
data_tst = data[-trainIndex,]
```


##### Random Forest

Helper functions for parameter tuning
```{r}
# get the best result from the result data frame
get_best_result = function(result_df) {
  best = which(result_df['Accuracy'] == max(result_df['Accuracy']))
  return(result_df[best,])
}


# tunning rf using preprocessing paramters
tune_rf = function(raw_data, cut_sizes, overlaps, nums_clusters, tst_trn_split){
  total_iter = length(cut_sizes) * length(overlaps) * length(overlaps)

  # only need to run once
  cv_5 = trainControl(method = "cv", number = 5)
  result = data.frame(matrix(1:6,ncol=6))
  colnames(result) = list("Cut size", "Overlap", "Num of features", "mtry", "Accuracy", "AccuracySD")
  result_idx = 1
  
  iter = 0
  start_time = Sys.time()
  
  # iterating through all possible parameters
  for (cut_size in cut_sizes){
    for (overlap in overlaps){
      for (num_clusters in nums_clusters){
        if (overlap >= cut_size){
          iter = iter + 1
          print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "mins. Total iter: ", total_iter))
          start_time = Sys.time()
          next
        }
        data = process_data(raw_data, cut_size=cut_size, overlap=overlap, num_clusters=num_clusters)
        data_trn = data[tst_trn_split,]
        data_tst = data[-tst_trn_split,]
        
        rf_cv_grid = expand.grid(mtry=1:num_clusters)
        rf_cv = train(class ~ . , data = data_trn,
                              method = "rf",
                              trControl = cv_5,
                              verbose = FALSE,
                              preProcess = c("center", "scale"),
                              tuneGrid = rf_cv_grid)
        
        for (row in 1:num_clusters){
          result[result_idx, ] = c(cut_size, overlap, num_clusters, rf_cv$results[row,1], rf_cv$results[row,2], rf_cv$results[row,4]) 
          result_idx = result_idx + 1
        }
        
        iter = iter + 1
        print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "s. Total iter: ", total_iter))
        start_time = Sys.time()
      }
    }
  }
  return(result)
}
```

Tunning rf model parameters(don't run it since it is super slow. Result are in the following chunk)
```{r eval=FALSE}
# tunning parameter grid, mtry is all the possible value
cut_sizes = list(1, 5, 10, 20)
overlaps = list(0, 3, 5)
nums_clusters = list(5, 10, 20)

# test train split to be passed to the tuning function
set.seed(59999)
trainIndex = createDataPartition(1:length(raw_data), p=0.7, list=FALSE,times=1)

# tunning function, retrun result in data from
rf_cv = tune_rf(data_matrix_raw, cut_sizes=cut_sizes, overlaps=overlaps, nums_clusters=nums_clusters, tst_trn_split=trainIndex)

# find the best result and train 
best_result = get_best_result(rf_cv)
```

Train with best result and test with testing set
```{r}
cv_5 = trainControl(method = "cv", number = 5)

#data = process_data(data_matrix_raw, cut_size=best_result$'Cut size', overlap=best_result$'Overlap', num_clusters=best_result$'Num of features')
data = process_data(data_matrix_raw, cut_size=1, overlap=0, num_clusters=20)
data_trn = data[trainIndex,]
data_tst = data[-trainIndex,]

#rf_final = randomForest(class~., data=data_trn, mtry=best_result$mtry)
rf_final = randomForest(class~., data=data_trn, mtry=8)
pred_rf = predict(rf_final, data_tst)

# return test set accuracy
cm_rf = confusionMatrix(pred_rf, data_tst$class)
cm_rf$table
cm_rf$overall['Accuracy']
```

```{r}
# test comment
cv_5 = trainControl(method = "cv", number = 5)
gbm_grid = expand.grid(interaction.depth = c(1, 2),
                       n.trees = c(500, 1000, 1500),
                       shrinkage = c(0.001, 0.01, 0.1),
                       n.minobsinnode = 10)

gbm_cv = train(class ~ ., data = data,
                      method = "gbm",
                      trControl = cv_5,
                      verbose = FALSE,
                      tuneGrid = gbm_grid)
pred = predict(gbm_cv)

# plot the confusion matrix
confusionMatrix(pred, data$class)
```

