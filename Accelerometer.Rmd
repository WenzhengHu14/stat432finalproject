---
title: "Main"
author: "Zach Quicksall (zsq2), Doyeon Kim (dkim172), Nick Favale (favale2), Wenzheng Hu(whu14)"
date: "4/10/2018"
output: html_document
---
```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(rlist)
library(flexclust)
library(gbm)
library(caret)
library(ape)
library(randomForest)
```

## Data preprocessing

```{r echo=FALSE}
# Load data
# use this to load raw data
load_data = function(data_path){
  num_action = 0
  # element n is the actual name of class n
  class_to_actions = list()
  data_matrix = list()
  index = 0
  
  # each row is a file, the first element of a row is its class(1-16), the rest are flattened (through each time unit) 3 dimension data
  
  for (action in list.files(path = data_path)){
    action_path = paste(data_path, action, sep = "/")
    num_action = num_action + 1
    class_to_actions[num_action] = action
    
    for (file in list.files(path = action_path)){
      file_name = paste(action_path, file, sep = "/")
      data = read.table(file_name)
      index = index + 1
      data_matrix[[index]] = c(num_action, as.list(t(data)))
    }
  }
  
  return(data_matrix)
}
```

Process data
```{r echo=FALSE}
# Process data
fit = function(input_data, cut_size, overlap=0, num_clusters){
  cutted_signals = list()
  index = 0
  for (observation in input_data){
    index = index + 1
    cutted_signals = c(cutted_signals, cut_signal(observation[-1], cut_size, overlap))
  }
  matrix_signals = matrix(unlist(cutted_signals), ncol=3*cut_size, byrow=T)
  model = flexclust::kcca(matrix_signals, k=num_clusters, kccaFamily("kmeans"))
  
  return(model)
}

cut_signal = function(input_data, cut_size, overlap=0){
  result_data = list()
  input_data_size = length(input_data)
  input_data_idx = 1
  result_data_idx = 1

  while (input_data_idx + cut_size*3 < input_data_size){
    result_data[[result_data_idx]] = input_data[input_data_idx:(input_data_idx+cut_size*3-1)]
    input_data_idx = input_data_idx + cut_size*3 - overlap*3
    result_data_idx = result_data_idx + 1
  }
  return(result_data)
}

# the returned data is a datafrane with num_clusters+1 columns. The last column is its label.
transform = function(model, input_data, cut_size, overlap, num_clusters){
  features = list()
  index = 0
  for (observation in input_data){
    index = index + 1
    cutted_signals = cut_signal(observation[-1], cut_size, overlap)
    matrix_signals = matrix(unlist(cutted_signals), ncol=3*cut_size, byrow=T)
    pred_clusters = predict(model, matrix_signals)
    feature = count_cluster(pred_clusters, num_clusters)
    feature[num_clusters+1] = observation[1]
    features[[index]] = feature
  }
  dt_features = data.frame(matrix(unlist(features), ncol=num_clusters+1, byrow=T))
  colnames(dt_features)[num_clusters+1] = "class"
  return(dt_features)
}

count_cluster = function(pred_clusters, num_clusters){
  feature = 1:num_clusters+1
  for (i in 1:num_clusters){
    feature[i] = sum(pred_clusters==i)
  }
  return(feature)
}

# use this to process data
process_data = function(data_matrix, data_path, cut_size, overlap, num_clusters){
  model = fit(data_matrix, cut_size, overlap, num_clusters)
  data = transform(model, data_matrix, cut_size, overlap, num_clusters)
  data['class'] = as.factor(data$class)
  return(data)
}
```

##### Load and preprocess data
```{r}
data_path = "HMP_Dataset"

# Load raw data from the data file
data_matrix_raw = load_data(data_path)

# Preprocess the data by Vector Quantization
# preprocess_data will be called multiple times in parameter tuning since parameter of preprocessing also need to be tuned
data = process_data(data_matrix_raw, cut_size=10, overlap=0, num_clusters=10)

# Test-train split
trainIndex = createDataPartition(data$class, p=0.7, list=FALSE,times=1)
data_trn = data[trainIndex,]
data_tst = data[-trainIndex,]
```

##### Random Forest

```{r echo=FLASE}
# Helper functions for parameter tuning to get the best result from the result data frame
get_best_result = function(result_df) {
  best = which(result_df['Accuracy'] == max(result_df['Accuracy']))
  return(result_df[best,])
}
```

```{r echo=FALSE}
# Tunning rf using preprocessing paramters
tune_rf = function(raw_data, cut_sizes, overlaps, nums_clusters, tst_trn_split){
  total_iter = length(cut_sizes) * length(overlaps) * length(overlaps)

  # only need to run once
  cv_5 = trainControl(method = "cv", number = 5)
  result = data.frame(matrix(1:6,ncol=6))
  colnames(result) = list("Cut size", "Overlap", "Num of features", "mtry", "Accuracy", "AccuracySD")
  result_idx = 1
  
  iter = 0
  start_time = Sys.time()
  
  # iterating through all possible parameters
  for (cut_size in cut_sizes){
    for (overlap in overlaps){
      for (num_clusters in nums_clusters){
        if (overlap >= cut_size){
          iter = iter + 1
          print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "mins. Total iter: ", total_iter))
          start_time = Sys.time()
          next
        }
        data = process_data(raw_data, cut_size=cut_size, overlap=overlap, num_clusters=num_clusters)
        data_trn = data[tst_trn_split,]
        data_tst = data[-tst_trn_split,]
        
        rf_cv_grid = expand.grid(mtry=1:num_clusters)
        rf_cv = train(class ~ . , data = data_trn,
                              method = "rf",
                              trControl = cv_5,
                              verbose = FALSE,
                              preProcess = c("center", "scale"),
                              tuneGrid = rf_cv_grid)
        
        for (row in 1:num_clusters){
          result[result_idx, ] = c(cut_size, overlap, num_clusters, rf_cv$results[row,1], rf_cv$results[row,2], rf_cv$results[row,4]) 
          result_idx = result_idx + 1
        }
        
        iter = iter + 1
        print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "s. Total iter: ", total_iter))
        start_time = Sys.time()
      }
    }
  }
  return(result)
}
```

Tunning rf model parameters with helper function tune_rf
```{r eval=FALSE}
# Tunning parameter grid, mtry is all the possible value (1 to num_clusters)
cut_sizes = list(1, 5, 10, 20)
overlaps = list(0, 3, 5)
nums_clusters = list(5, 10, 20)

# Test train split to be passed to the tuning function
set.seed(59999)
trainIndex = createDataPartition(1:length(data_matrix_raw), p=0.7, list=FALSE,times=1)

# Tunning function, retrun result in data from
rf_cv = tune_rf(data_matrix_raw, cut_sizes=cut_sizes, overlaps=overlaps, nums_clusters=nums_clusters, tst_trn_split=trainIndex)

# Find the best result and train 
best_result = get_best_result(rf_cv)
```

Train with best result from previous chunck and test with testing set
```{r}
cv_5 = trainControl(method = "cv", number = 5)

# Preprocess data with best parameters
data = process_data(data_matrix_raw, cut_size=1, overlap=0, num_clusters=20)
data_trn = data[trainIndex,]
data_tst = data[-trainIndex,]

# Train the rf with the preprocessed data with best parameters and predict the test data
rf_final = randomForest(class~., data=data_trn, mtry=8)
pred_rf = predict(rf_final, data_tst)

# Return test set accuracy
cm_rf = confusionMatrix(pred_rf, data_tst$class)
cm_rf$table
cm_rf$overall['Accuracy']
```

##### Support Vector Machine

```{r}
# Linear SVM
#lin_svm_grid = expand.grid(C = c(1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000))
best_lin_svm_grid = expand.grid(C = c(1000))

lin_svm_mod = train(class ~ .,
                    data = data_trn,
                    method = "svmLinear",
                    preProcess = c("center","scale"),
                    trControl = trainControl(method = "none"),
                    tuneGrid = best_lin_svm_grid,
                    verbose = FALSE)

lin_test_pred = predict(lin_svm_mod, data_tst)
confusionMatrix(lin_test_pred, data_tst$class)
```

```{r}
# Polynomial SVM
poly_svm_grid = expand.grid(degree = c(2,3,4,5),
                            scale = c(1, 1e-1, 1e-2, 1e-3, 1e-4),
                            C = c(1e-2, 1e-1, 1, 10, 100))

best_poly_svm_grid = expand.grid(degree = c(2),
                            scale = c(1),
                            C = c(10))

poly_svm_mod = train(class ~ .,
                    data = data_trn,
                    method = "svmPoly",
                    preProcess = c("center","scale"),
                    trControl = trainControl(method = "none"),
                    tuneGrid = best_poly_svm_grid,
                    verbose = FALSE)

poly_test_pred = predict(poly_svm_mod, data_tst)
confusionMatrix(poly_test_pred, data_tst$class)
```

```{r}
# Gaussian Kernel SVM

best_rbf_svm_grid = expand.grid(C = c(512),
                                sigma = c(0.5047778))

rbf_svm_mod = train(class ~ .,
                    data = data_trn,
                    method = "svmRadial",
                    preProcess = c("center","scale"),
                    trControl = trainControl(method = "none"),
                    tuneGrid = best_rbf_svm_grid,
                    verbose = FALSE)

rbf_test_pred = predict(rbf_svm_mod, data_tst)
confusionMatrix(rbf_test_pred, data_tst$class)
```

##### K-Nearest Neighbors

```{r}
# tune KNN model
tune_knn = function(raw_data, cut_sizes, overlaps, nums_clusters, tst_trn_split){
  total_iter = length(cut_sizes) * length(overlaps) * length(overlaps)

  result_idx = 1
  
  iter = 0
  start_time = Sys.time()
  
  # iterating through all possible parameters
  for (cut_size in cut_sizes){
    for (overlap in overlaps){
      for (num_clusters in nums_clusters){
        if (overlap >= cut_size){
          iter = iter + 1
          print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "mins. Total iter: ", total_iter))
          start_time = Sys.time()
          next
        }
        data = process_data(raw_data, cut_size=cut_size, overlap=overlap, num_clusters=num_clusters)
        data_trn = data[tst_trn_split,]
        data_tst = data[-tst_trn_split,]
        
knn_cv = train(class ~ ., data = data_trn,
               method = "knn",
               trControl = cv_5,
               verbose = FALSE,
               preProcess = c("center", "scale"),
               tuneGrid = expand.grid(k = c(1:100)))
        
        for (row in 1:num_clusters){
          result[result_idx, ] = c(cut_size, overlap, num_clusters, knn_cv$results[row,1], knn_cv$results[row,2], knn_cv$results[row,4]) 
          result_idx = result_idx + 1
        }
        
        iter = iter + 1
        print(paste("Iteration: ", iter, "finished in ", Sys.time()-start_time, "s. Total iter: ", total_iter))
        start_time = Sys.time()
      }
    }
  }
  return(result)
}
```

```{r}
# KNN results

cv_5 = trainControl(method = "cv", number = 5)

knn_final = train(class ~ ., data = data_trn,
               method = "knn",
               trControl = cv_5,
               preProcess = c("center", "scale"),
               tuneGrid = expand.grid(k = c(3:100)))
pred_knn = predict(knn_final, data_tst)

# return test set accuracy
cm_knn = confusionMatrix(pred_knn, data_tst$class)
cm_knn$table
cm_knn$overall['Accuracy']
cval = as.integer(which.max(knn_final$results$Accuracy))
```

```{r}
# validate KNN results

knn_final_2 = train(class ~ ., data = data_trn,
               method = "knn",
               trControl = trainControl(method = "none"),
               preProcess = c("center", "scale"),
               tuneGrid = expand.grid(k = cval + 2))
pred_knn_2 = predict(knn_final_2, data_tst)

cm_knn_2 = confusionMatrix(pred_knn_2, data_tst$class)
cm_knn_2$table
cm_knn_2$overall['Accuracy']
```

##### GBM

```{r}
# GBM Grid/Parameter
gbm_grid = expand.grid(interaction.depth = 8,
                       n.trees = 1038,
                       shrinkage = 0.01,
                       n.minobsinnode = 10)

# 5-folds GBM Model
gbm_model_cv = train(class ~ ., 
                     data = data_trn, 
                     method = "gbm",
                     trControl = trainControl(method = "cv", number = 5),
                     tuneGrid = gbm_grid,
                     verbose = FALSE)

# Tuning Parameter
gbm_model_cv$bestTune

# Accuracy
get_best_result(gbm_model_cv)
<<<<<<< HEAD
=======

gbm_test_pred = predict(gbm_model_cv, data_tst)
confusionMatrix(gbm_test_pred, data_tst$class)
```



>>>>>>> 2d406d9187dfed41a3e01c769a51003f621a2964

gbm_test_pred = predict(gbm_model_cv, data_tst)
confusionMatrix(gbm_test_pred, data_tst$class)
```








